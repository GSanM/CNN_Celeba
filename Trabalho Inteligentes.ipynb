{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Basics\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Keras\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carrega dataset com Pandas\n",
    "df = pd.read_csv('/home/gabriel/Documents/Projetos/SisIntel/Trabalho/list_attr_celeba.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para balanceamento o dataset (undersampling)\n",
    "male = df[df['Attractive'] == 1][['image_id','Attractive']].sample(10000)\n",
    "female = df[df['Attractive'] == -1][['image_id','Attractive']].sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePaths = pd.concat([male[['image_id']], female[['image_id']]], axis=0)\n",
    "labels = pd.concat([male[['Attractive']], female[['Attractive']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get images\n",
    "data = []\n",
    "labels = labels['Attractive'].values.tolist()\n",
    "for imagePath in imagePaths['image_id']:\n",
    "    image = cv2.imread(\"/home/gabriel/Documents/Projetos/SisIntel/Trabalho/img_align_celeba/\" + imagePath)\n",
    "    image = cv2.resize(image, (32, 32))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide em train e validation com .8 train e .2 test\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(data), labels, test_size=.2)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "y_train = np.clip(y_train, 0, 1)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, num_classes=2)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 32, 32, 3) (16000, 2)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_18 (InputLayer)           (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 32, 32, 64)   1792        input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 32, 32, 64)   1792        input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling2D) (None, 32, 32, 3)    0           input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 16, 16, 64)   36928       conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 16, 16, 64)   102464      conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 16, 16, 64)   1792        max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 16, 48, 64)   0           conv2d_87[0][0]                  \n",
      "                                                                 conv2d_89[0][0]                  \n",
      "                                                                 conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 49152)        0           concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 2)            98306       flatten_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 243,074\n",
      "Trainable params: 243,074\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Modelo\n",
    "input_img = Input(shape = (32, 32, 3))\n",
    "\n",
    "tower_1 = Conv2D(64, (3,3), padding='same', activation='relu')(input_img)\n",
    "tower_1 = Conv2D(64, (3,3), padding='same', strides=(2,2), activation='relu')(tower_1) \n",
    "\n",
    "tower_2 = Conv2D(64, (3,3), padding='same', activation='relu')(input_img)\n",
    "tower_2 = Conv2D(64, (5,5), padding='same', strides=(2,2), activation='relu')(tower_2)\n",
    "\n",
    "tower_3 = MaxPooling2D((3,3), strides=(1,1), padding='same')(input_img)\n",
    "tower_3 = Conv2D(64, (3,3), padding='same', strides=(2,2), activation='relu')(tower_3)\n",
    "\n",
    "output = concatenate([tower_1, tower_2, tower_3], axis = 2)\n",
    "\n",
    "output = Flatten()(output)\n",
    "out    = Dense(2, activation='softmax')(output)\n",
    "\n",
    "model = Model(inputs = input_img, outputs = out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurações\n",
    "epochs = 5\n",
    "lrate = 0.01\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/5\n",
      "16000/16000 [==============================] - 170s 11ms/step - loss: 0.5786 - acc: 0.6962 - val_loss: 0.7216 - val_acc: 0.6182\n",
      "Epoch 2/5\n",
      "16000/16000 [==============================] - 175s 11ms/step - loss: 0.5176 - acc: 0.7451 - val_loss: 0.9135 - val_acc: 0.5118\n",
      "Epoch 3/5\n",
      "16000/16000 [==============================] - 167s 10ms/step - loss: 0.4926 - acc: 0.7586 - val_loss: 1.1641 - val_acc: 0.4363\n",
      "Epoch 4/5\n",
      "16000/16000 [==============================] - 178s 11ms/step - loss: 0.4782 - acc: 0.7708 - val_loss: 1.1206 - val_acc: 0.4537\n",
      "Epoch 5/5\n",
      "16000/16000 [==============================] - 179s 11ms/step - loss: 0.4694 - acc: 0.7749 - val_loss: 0.9125 - val_acc: 0.5570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f80ea5606a0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Treino\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvar pesos\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(os.path.join(os.getcwd(), 'model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 55.70%\n"
     ]
    }
   ],
   "source": [
    "#Acurácia\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
